Next we prepare the pronunciation dictionary. 
Its purpose is to supply the mapping from the transcription text
in \verb!data/local/text! to a sequence of phones, each of which
in turn corresponds with a hidden Markov model providing
the phone's pronunciation.
The dictionary consists of a directory \verb!data/local/dict!
containing all the files described in this section.
In the \verb!iban! example these files
are created by the script \verb!local/prepare_dict.sh!.

First one prepares a file \verb!lexicon.txt! specifying
the pronunciations of some subset
of the words found in \verb!data/train/text!.
Naturally one is most interested in pronunciations
of the most common words, so it would be natural
to first order all the words of \verb!data/train/text! by
their frequencies, and then select, say, the 10,000 most common words
to be included in \verb!lexicon.txt!.
Note that the lexicon should {\em not} explicitly contain words
from \verb!data/test/text!. This affords the opportunity
to invoke another mechanism during testing,
namely the {\em unknown model}, which will be used to determine
the pronunciations of out-of-vocabulary words.

Each line of \verb!lexicon.txt! contains a word, followed by a space or tab,
followed by a sequence of phones, represented by tokens taken from a fixed
pronunciation alphabet.
The choice of this alphabet is not imposed by \textsf{Kaldi}, but should
be such that each phone is transcribed consistently every time it appears
in a word.
For example, the first ten lines of \verb!lexicon.txt! are shown
below, from \verb!iban! on the left, and from \verb!wsj! on the right.

\begin{multicols}{2}
\begin{verbatim}
<sil>   SIL
<UNK>   SIL
ke      k @
nya     NJ a KK
iya     i j a
ba      b a KK
dua     d u w a
sida    s i d a KK
puluh   p u l u @ h
raban   r a b a n
\end{verbatim}
\begin{verbatim}
A42128  EY1 F AO1 R T UW1 W AH1 N T UW1 EY1 T
AAA  T R IH2 P AH0 L EY1
AABERG  AA1 B ER0 G
AACHEN  AA1 K AH0 N
AACHENER  AA1 K AH0 N ER0
A  AH0
AAKER  AA1 K ER0
AALSETH  AA1 L S EH0 TH
AAMODT  AA1 M AH0 T
AANCOR  AA1 N K AO2 R
\end{verbatim}
\end{multicols}

In the case of \verb!wsj! the pronunciations were extracted
from a dictionary that \verb!run.sh! downloaded from \verb!cmu.edu!.
In the case of \verb!iban! the pronunciations were provided
in the dataset. Another choice is to compose \verb!lexicon.txt!
by hand in case a pronunciation dictionary is unavailable.
Still another choice is to simply use the sequence of
letters of each word as a surrogate for its pronunciation.
This works well for {\em phonetic} languages
such as Spanish, since each letter is usually
pronounced in the same way.

Note also that \verb!lexicon.txt! from \verb!iban! also contains
entries for two special phones, \verb!<sil>! and \verb!<UNK>!,
both having pronunciation \verb!SIL!.
These entries cause \textsf{Kaldi} to invoke special models,
namely the {\em silence model}, which models the acoustic properties
of the speaker's physical environment, and the unknown
model mentioned above.

Each of the tokens representing phones in \verb!lexicon.txt!
is expected to be listed in one the files
\verb!nonsilence_phones.txt!,
\verb!silence_phones.txt!, or
\verb!optional_silence.txt!.
In this way phonetic transcriptions can be mapped to integer
sequences, the integers referring to line numbers in these files.
The file \verb!silence_phones! specifies
which phones should invoke the silence model.
Multiple types of silence could be modeled by introducing
special symbols in the file \verb!optional_silence!.
However, in the \verb!iban! example both
\verb!silence_phones.txt! and \verb!optional_silence.txt!
contain only \verb!SIL!.

The pronunciation of a given phone varies widely,
even by the same speaker. \textsf{Kaldi} handles this by creating
multiple HMMs for each phone, and choosing among them with the help
of a {\em decision tree}. Starting at the root of the tree, one traverses
the tree, choosing among branches according to responses to specific
questions about the usage of the phone, arriving finally at a leaf
labeled by an HMM.
The questions labeling branch points
in the tree are listed in the file \verb!extra_quesitons!.

One frequent source of phonemic variation is the context of a phone.
If this is the case (as it is in the \verb!iban! example)
\verb!extra_quesitons! would specify branching decisions based on the context
of the phone, as implemented by the postfixes
\verb!_B! (for word-initial),
\verb!_I! (for word-internal),
\verb!_E! (for word-final),
\verb!_S! (for standalone).
In the case of a tonal language the file could be used to pose
questions about rising or falling tone.

This concludes the preparation of the dictionary directory.
Next the main script \verb!run.sh! calls \verb!utils/prepare_lang.sh!
which creates the remainder of the files described in this section.

The file \verb!lexiconp.txt! is used to allow a word to have multiple
pronunciations. After counting occurrences of each variation
in the training corpus, the file specifies its relative
frequency along with its pronunciation sequence, now decorated
by the various symbols enumerated in \verb!extra_questions!.

Merely specifying the pronunciation of each word
would make it impossible to distinguish among homophones, such
as the English words {\em two} and {\em too}.
\textsf{Kaldi} handles this ambiguity
using disambugiation symbols.
Namely, it lists each word in \verb!lexiconp_disambig.txt!,
along with the sequence of phones specifying its pronunciation,
as listed in \verb!lexiconp.txt!, now
with homophones distinguished by appending special tokens
\verb!#1!, \verb!#2!, etc to the pronunciation strings when needed.
For example, the first few lines of this file are shown below.
\begin{verbatim}
<sil> 1.0 SIL_S #1
<UNK> 1.0 SIL_S #2
ke  1.0 k_B @_E
nya 1.0 NJ_B a_I KK_E
iya 1.0 i_B j_I a_E
ba  1.0 b_B a_I KK_E #1
dua 1.0 d_B u_I w_I a_E
sida  1.0 s_B i_I d_I a_I KK_E
\end{verbatim}
Later in the same file one finds the line
\begin{verbatim}
bak 1.0 b_B a_I KK_E #2
\end{verbatim}
telling us that the words {\em ba} and {\em bak}
have the same pronunciation.
Finally the file specifies the proportion of the time
each instance of a homophone occurs, although these numbers
have been modified so that the minimum is scaled to \verb!1.0!.

\verb!phones.txt! and \verb!words.txt! map all the possible phones
and words into integers. All references to phones and words
apply the mapping given by these files for computational efficiency.

Finally, the \verb!data/lang/topo! specifies the initial HMM
for each phone in each of its variations.
Here \verb!topo! stands for {\em topology} the term not used
in its normal mathematical usage.
Rather than display the file, we interpret it as follows.
Each non-silence phone will be modeled by an HMM
whose transitions $a_{ij}$ are initially as
shown in \autoref{NonSilence}
and whose emission probabilities $b_t\left(j\right)$
are referenced in the file.
Each silence phone is initially given a more complicated topology,
whose transitions are shown in \autoref{Silence}.

\begin{figure}
\label{NonSilence}
\begin{center}
\digraph[scale=0.5]{nonsilenceHmm}{
rankdir=LR;
{ node [shape="doublecircle"] 3;}
{ node [shape="circle"] 0 1 2}
0->0 [label="0.75"];
0->1 [label="0.25"];
1->1 [label="0.75"];
1->2 [label="0.25"];
2->2 [label="0.75"];
2->3 [label="0.25"];
}
\end{center}
\caption{Hidden Markov model for a nonsilence phone}
\end{figure}

\begin{figure}
\label{Silence}
\begin{center}
\digraph[scale=0.5]{silenceHmm}{
rankdir=LR;
{ node [shape="doublecircle"] 5;}
{ node [shape="circle",rank="same"] 1 2 3 4}
{ node [shape="circle"] 0 5}
0->0 [label="0.25"];
0->1 [label="0.25"];
0->2 [label="0.25"];
0->3 [label="0.25"];
1->1 [label="0.25"];
1->2 [dir="both",label="0.25"];
1->3 [dir="both",label="0.25"];
1->4 [label="0.25"];
2->2 [label="0.25"];
2->3 [dir="both",label="0.25"];
2->4 [label="0.25"];
3->3 [label="0.25"];
3->4 [label="0.25"];
4->4 [label="0.25"];
4->5 [label="0.75"];
}
\end{center}
\caption{Hidden Markov model for a silence phone}
\end{figure}
